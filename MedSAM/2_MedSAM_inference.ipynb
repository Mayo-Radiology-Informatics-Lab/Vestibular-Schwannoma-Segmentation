{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will:\n",
    "\n",
    "1. Define helper functions for calculating bounding boxes, converting images to 3 channels, cropping images, and plotting comparisons.\n",
    "2. Load MRI and label data, compute 3D bounding boxes, and derive slice-level bounding boxes.\n",
    "3. Use a model (assumed to be defined externally as bbox_prompt) to infer a segmentation mask for each slice within the bounding box region.\n",
    "4. Save the predicted segmentation results and visualize them alongside the ground truth masks and bounding boxes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Extract Model - Checkpoint Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command uses the `extract_weights.py` script to convert a model checkpoint file into an extracted version compatible with MedSAM.\n",
    "\n",
    "Adjust the input (`-from_pth`) and output (`-to_pth`) paths as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/research/projects/Sahika/MedSAM/utils/extract_weights.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  from_pth = torch.load(from_pth, map_location='cpu')\n",
      "Weights are saved to /research/projects/Sahika/MedSAM/work_dir/MedSAM-ViT-B-20240925-2309/medsam_model_best_extracted.pth\n"
     ]
    }
   ],
   "source": [
    "!python /path/to/MedSAM/utils/extract_weights.py \\\n",
    "    -from_pth /path/to/MedSAM/work_dir/MedSAM-ViT-B-YYYYMMDD-HHMM/medsam_model_best.pth \\\n",
    "    -to_pth /path/to/MedSAM/work_dir/MedSAM-ViT-B-YYYYMMDD-HHMM/medsam_model_best_extracted.pth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"<MODEL_PATH>\"                     # Path to the trained model, e.g., 'path/to/medsam_model_best_extracted.pth'\n",
    "test_mri_dir = \"<MRI_DIR>\"                      # Path to the MRI test images, e.g., 'path/to/imagesTs'\n",
    "ground_truth_dir = \"<GROUND_TRUTH_DIR>\"         # Path to the ground truth masks, e.g., 'path/to/labelsTs'\n",
    "predicted_masks_dir = \"<PREDICTED_MASKS_DIR>\"   # Directory to save predicted masks, e.g., 'path/to/labelsTs_pred'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tum modeller 7 cm kup icin egitildiginden dolayi evaluation asamasinda ayni alani degerlendirmek amaciyla ground truth label klavuzunda roinin tespiti icin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculate_bounding_box_with_margin_3d function finds the smallest 3D bounding box that contains all non-zero elements in a 3D mask volume. A margin is added in the x and y dimensions to include some surrounding area, but the z-dimension range remains fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bounding_box_with_margin_3d(mask_data, margin=10):\n",
    "    \"\"\"\n",
    "    Calculate a 3D bounding box around the non-zero mask regions.\n",
    "    Adds a specified margin in the x and y dimensions only.\n",
    "    \n",
    "    Parameters:\n",
    "        mask_data (np.ndarray): 3D mask array.\n",
    "        margin (int): Margin to add around the bounding box in x and y directions.\n",
    "        \n",
    "    Returns:\n",
    "        list or None: [x_min, y_min, z_min, x_max, y_max, z_max] if found, else None.\n",
    "    \"\"\"\n",
    "    coords = np.nonzero(mask_data)\n",
    "    if coords[0].size == 0:  # Empty mask\n",
    "        return None\n",
    "\n",
    "    z_min, z_max = np.min(coords[2]), np.max(coords[2])\n",
    "    y_min, y_max = np.min(coords[0]), np.max(coords[0])\n",
    "    x_min, x_max = np.min(coords[1]), np.max(coords[1])\n",
    "\n",
    "    # Add margin to x and y dimensions only\n",
    "    y_min = max(y_min - margin, 0)\n",
    "    y_max = min(y_max + margin, mask_data.shape[0] - 1)\n",
    "    x_min = max(x_min - margin, 0)\n",
    "    x_max = min(x_max + margin, mask_data.shape[1] - 1)\n",
    "\n",
    "    return [x_min, y_min, z_min, x_max, y_max, z_max]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a 3D bounding box, we  need to extract a 2D bounding box for a specific slice (z-index). The calculate_slice_bounding_box function uses the 3D coordinates but returns a 2D bounding box applicable for a single slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_slice_bounding_box(bbox_3d, slice_index):\n",
    "    \"\"\"\n",
    "    Extract the 2D bounding box from a 3D bounding box for a given slice (z-index).\n",
    "    \n",
    "    Parameters:\n",
    "        bbox_3d (list): [x_min, y_min, z_min, x_max, y_max, z_max].\n",
    "        slice_index (int): The slice (z) index.\n",
    "        \n",
    "    Returns:\n",
    "        list: [x_min, y_min, x_max, y_max] for the given slice.\n",
    "    \"\"\"\n",
    "    x_min, y_min, z_min, x_max, y_max, z_max = bbox_3d\n",
    "    return [x_min, y_min, x_max, y_max]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MRI slices are often single-channel (grayscale) images. The convert_to_3_channel function replicates the grayscale data into 3 channels so that we can treat it as a 3-channel image if needed (e.g., for visualization or models expecting multiple channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_3_channel(grayscale_image):\n",
    "    \"\"\"\n",
    "    Convert a 2D grayscale image to a 3-channel image by stacking it along a new axis.\n",
    "    \n",
    "    Parameters:\n",
    "        grayscale_image (np.ndarray): 2D image.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: 3D image with shape (H, W, 3).\n",
    "    \"\"\"\n",
    "    return np.stack([grayscale_image] * 3, axis=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crop_image_with_bbox function crops a 2D image slice using a given bounding box. It ensures that the bounding box coordinates are within the image boundaries and returns the cropped image region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_with_bbox(img_slice, bbox):\n",
    "    \"\"\"\n",
    "    Crop a 2D image slice based on the given bounding box.\n",
    "    \n",
    "    Parameters:\n",
    "        img_slice (np.ndarray): 2D image slice.\n",
    "        bbox (list): [x_min, y_min, x_max, y_max].\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Cropped 2D image.\n",
    "    \"\"\"\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    x_min = int(max(x_min, 0))\n",
    "    y_min = int(max(y_min, 0))\n",
    "    x_max = int(min(x_max, img_slice.shape[1]))\n",
    "    y_max = int(min(y_max, img_slice.shape[0]))\n",
    "\n",
    "    print(f\"Cropping with bbox: x_min={x_min}, y_min={y_min}, x_max={x_max}, y_max={y_max}\")\n",
    "    if x_min < x_max and y_min < y_max:\n",
    "        cropped_img = img_slice[y_min:y_max, x_min:x_max]\n",
    "        print(f\"Cropped image size: {cropped_img.shape}\")\n",
    "        return cropped_img\n",
    "    else:\n",
    "        print(\"Invalid bounding box, returning original image.\")\n",
    "        return img_slice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot_comparison function helps visualize and compare the original image slice, ground truth mask, predicted mask, and the cropped image side-by-side. It also draws the bounding box onto the displayed images for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(img_slice_3ch, gt_slice, pred_mask, cropped_img, bbox):\n",
    "    \"\"\"\n",
    "    Plot the original image, ground truth mask, predicted mask, and cropped image side-by-side.\n",
    "    Overlays bounding boxes and masks for visual comparison.\n",
    "    \n",
    "    Parameters:\n",
    "        img_slice_3ch (np.ndarray): 3-channel image slice.\n",
    "        gt_slice (np.ndarray): Ground truth mask for the slice.\n",
    "        pred_mask (np.ndarray): Predicted segmentation mask.\n",
    "        cropped_img (np.ndarray): Cropped image portion.\n",
    "        bbox (list): [x_min, y_min, x_max, y_max] bounding box for visualization.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Original Image\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(img_slice_3ch[:, :, 0], cmap='gray')\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    if bbox:\n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "        ax = plt.gca()\n",
    "        rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, \n",
    "                                 linewidth=2, edgecolor='yellow', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    # Ground Truth Mask Overlay\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(img_slice_3ch[:, :, 0], cmap='gray', alpha=0.7)\n",
    "    plt.imshow(gt_slice, cmap='Reds', alpha=0.3)\n",
    "    plt.title('Ground Truth Mask Overlay')\n",
    "    plt.axis('off')\n",
    "    if bbox:\n",
    "        ax = plt.gca()\n",
    "        rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, \n",
    "                                 linewidth=0.5, edgecolor='yellow', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    # Predicted Mask Overlay\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(img_slice_3ch[:, :, 0], cmap='gray', alpha=0.7)\n",
    "    plt.imshow(pred_mask, cmap='Blues', alpha=0.3)\n",
    "    plt.title('Predicted Mask Overlay')\n",
    "    plt.axis('off')\n",
    "    if bbox:\n",
    "        ax = plt.gca()\n",
    "        rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, \n",
    "                                 linewidth=0.5, edgecolor='yellow', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    # Cropped Image\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(cropped_img, cmap='gray')\n",
    "    plt.title('Cropped Original Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Main Processing Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Description:\n",
    "\n",
    "1. Iterate over files in image_dir looking for MRI volumes (_0000.nii.gz pattern).\n",
    "2. For each volume, load its corresponding label file.\n",
    "3. Compute a 3D bounding box around the non-zero regions in the label.\n",
    "4. Iterate over slices within the bounding box (z_min to z_max).\n",
    "5. For each slice:\n",
    "    1. Convert the slice to a 3-channel image.\n",
    "    2. Compute the slice-level bounding box.\n",
    "    3. Use the model (bbox_prompt) to predict a mask within this bounding box.\n",
    "    4. Save the predicted mask as a NIfTI file.\n",
    "    5. Crop the image using the bounding box.\n",
    "    6. Plot the original slice, ground truth, prediction, and cropped image for visual inspection.\n",
    "    7. Stop after a certain number of slices to limit processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined paths and model setup\n",
    "image_dir = \"path_to_images\"\n",
    "label_dir = \"path_to_labels\"\n",
    "output_dir = \"path_to_output\"\n",
    "bbox_prompt = ...  # Your model or object implementing _set_image() and _infer()\n",
    "\n",
    "count = 0\n",
    "stop_processing = False\n",
    "\n",
    "for image_file in os.listdir(image_dir):\n",
    "    print(image_file)\n",
    "    if stop_processing:\n",
    "        break\n",
    "\n",
    "    if image_file.endswith('_0000.nii.gz'):\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "        label_name = image_file.replace('_0000.nii.gz', '.nii.gz')\n",
    "        label_path = os.path.join(label_dir, label_name)\n",
    "\n",
    "        label_img = nib.load(label_path)\n",
    "        label_data = label_img.get_fdata()\n",
    "\n",
    "        mri_img = nib.load(image_path)\n",
    "        mri_data = mri_img.get_fdata()\n",
    "\n",
    "        bounding_box_3d = calculate_bounding_box_with_margin_3d(label_data, margin=1)\n",
    "        if bounding_box_3d is None:\n",
    "            print(f\"No bounding box for {image_file}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Initialize an empty array to store the predicted masks\n",
    "        pred_mask_volume = np.zeros_like(mri_data)\n",
    "\n",
    "        # Loop over each slice in the 3D image within the bounding box range\n",
    "        x_min, y_min, z_min, x_max, y_max, z_max = bounding_box_3d\n",
    "        for z in range(z_min, z_max + 1):\n",
    "            slice_data = label_data[:, :, z]\n",
    "            if np.sum(slice_data) == 0:\n",
    "                # If no mask is found, continue and leave slice as zeros\n",
    "                continue\n",
    "\n",
    "            # Extract the current 2D slice\n",
    "            img_slice = mri_data[:, :, z]\n",
    "\n",
    "            # Convert to 3-channel image for the model\n",
    "            img_slice_3ch = convert_to_3_channel(img_slice)\n",
    "\n",
    "            # Set the image in the BboxPromptDemo\n",
    "            bbox_prompt._set_image(img_slice_3ch)\n",
    "\n",
    "            # Get prediction from MedSAM\n",
    "            with torch.no_grad():\n",
    "                predicted_mask = bbox_prompt._infer([x_min, y_min, x_max, y_max])\n",
    "\n",
    "            # Add the predicted mask to the volume\n",
    "            pred_mask_volume[:, :, z] = predicted_mask.astype(np.uint8)\n",
    "\n",
    "        # Save the predicted mask volume as a NIfTI file\n",
    "        pred_nifti = nib.Nifti1Image(pred_mask_volume, mri_img.affine)\n",
    "        output_path = os.path.join(output_dir, f\"{image_file.replace('_0000.nii', '.nii')}\")\n",
    "        nib.save(pred_nifti, output_path)\n",
    "\n",
    "        print(f\"Saved predicted mask for {image_file} to {output_path}\")\n",
    "\n",
    "print('Segmentation complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Evaluate Model Performance\n",
    "\n",
    "This section uses the `nnUNetv2_result.py` script to evaluate the model's segmentation performance. The script calculates metrics like Dice score and groups tumors by size using specified thresholds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define placeholders for paths\n",
    "csv_path = \"<CSV_PATH>\"      # Path to the dataset CSV file, e.g., 'path/to/dataset.csv'\n",
    "                                # This CSV file should contain all dataset information, \n",
    "                                # including at least the following columns:\n",
    "                                # - 'file_name': Names or paths of the MRI files.\n",
    "                                # - 'tumor_volume': Corresponding tumor volume measurements.\n",
    "\n",
    "thresholds = \"[200,400]\"  # Thresholds for grouping tumors by size:\n",
    "                          # - <200: Small tumors\n",
    "                          # - 200-400: Medium tumors\n",
    "                          # - >400: Large tumors\n",
    "\n",
    "# Function to call the nnUNetv2_result command dynamically\n",
    "def run_nnUNetv2_result(gt, pred, csv, thresholds):\n",
    "    \"\"\"\n",
    "    Run the nnUNetv2_result script with specified parameters.\n",
    "\n",
    "    Args:\n",
    "        gt (str): Path to the ground truth masks.\n",
    "        pred (str): Path to the predicted masks.\n",
    "        csv (str): Path to the CSV file.\n",
    "        thresholds (str): Threshold values in the format '[200,400]'.\n",
    "    \"\"\"\n",
    "    command = f'python3 nnUNetv2_result.py -gt {gt} -pred {pred} -csv {csv} -th {thresholds}'\n",
    "    try:\n",
    "        # Run the shell command\n",
    "        result = subprocess.run(command, shell=True, check=True, capture_output=True, text=True)\n",
    "        # Print the output\n",
    "        print(result.stdout)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error occurred: {e.stderr}\")\n",
    "\n",
    "# Call the function for the test set\n",
    "print(\"Running nnUNetv2_result for the test set...\")\n",
    "run_nnUNetv2_result(ground_truth_dir, predicted_masks_dir, csv_path, thresholds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Visualize Results\n",
    "\n",
    "We visualize three key slices from the MRI:\n",
    "1. First Quarter Slice,\n",
    "2. Middle Slice,\n",
    "3. Third Quarter Slice.\n",
    "\n",
    "For each slice, the following are shown:\n",
    "1. Original MRI Image.\n",
    "2. Ground Truth Overlay.\n",
    "3. Predicted Mask Overlay.\n",
    "4. Combined Ground Truth and Prediction Overlay.\n",
    "\n",
    "The visualizations are presented in a grid layout for easy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a NIfTI image\n",
    "def load_nifti_image(filepath):\n",
    "    image = sitk.ReadImage(filepath)\n",
    "    return sitk.GetArrayFromImage(image)\n",
    "\n",
    "# Function to apply the same validation transforms to both ground truth and predicted images\n",
    "def apply_test_transforms(image_file, label_file, test_transforms):\n",
    "    val_data = {\"image\": image_file, \"label\": label_file}\n",
    "    transformed = test_transforms(val_data)\n",
    "    return transformed[\"image\"], transformed[\"label\"]\n",
    "\n",
    "def visualize_slices_grid(image, ground_truth, prediction):\n",
    "    \"\"\"\n",
    "    Visualize slices in a grid:\n",
    "    1st row: First quarter slice\n",
    "    2nd row: Middle slice\n",
    "    3rd row: Third quarter slice\n",
    "\n",
    "    Each row contains:\n",
    "    1. Original Image\n",
    "    2. Ground Truth Overlay\n",
    "    3. Predicted Mask Overlay\n",
    "    4. Combined Overlay\n",
    "    \"\"\"\n",
    "    # Calculate slice indices dynamically\n",
    "    num_slices = image.shape[0]\n",
    "    slice_indices = [num_slices // 4, num_slices // 2, 3 * num_slices // 4]\n",
    "\n",
    "    plt.figure(figsize=(24, 18))  # Adjust figure size for three rows\n",
    "\n",
    "    for row_idx, slice_idx in enumerate(slice_indices):\n",
    "        # Extract slices\n",
    "        if len(image.shape) == 3:  # 3D MRI\n",
    "            image_slice = image[slice_idx, :, :]\n",
    "            gt_slice = ground_truth[slice_idx, :, :]\n",
    "            pred_slice = prediction[slice_idx, :, :]\n",
    "     \n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected image shape: {image.shape}\")\n",
    "\n",
    "        # Original Image\n",
    "        plt.subplot(3, 4, row_idx * 4 + 1)\n",
    "        plt.imshow(image_slice, cmap='gray')\n",
    "        plt.title(f'Original Image - Slice {slice_idx}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Ground Truth Overlay\n",
    "        plt.subplot(3, 4, row_idx * 4 + 2)\n",
    "        plt.imshow(image_slice, cmap='gray', alpha=0.8)\n",
    "        plt.imshow(gt_slice, cmap='Reds', alpha=0.2)\n",
    "        plt.title(f'Ground Truth - Slice {slice_idx}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Predicted Mask Overlay\n",
    "        plt.subplot(3, 4, row_idx * 4 + 3)\n",
    "        plt.imshow(image_slice, cmap='gray', alpha=0.8)\n",
    "        plt.imshow(pred_slice, cmap='Blues', alpha=0.2)\n",
    "        plt.title(f'Predicted Mask - Slice {slice_idx}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Combined Overlay (Ground Truth + Predicted)\n",
    "        plt.subplot(3, 4, row_idx * 4 + 4)\n",
    "        plt.imshow(image_slice, cmap='gray', alpha=0.8)\n",
    "        plt.imshow(gt_slice, cmap='Reds', alpha=0.2)\n",
    "        plt.imshow(pred_slice, cmap='Blues', alpha=0.2)\n",
    "        plt.title(f'Combined Overlay - Slice {slice_idx}')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basename = next((f for f in os.listdir(test_mri_dir) if f.endswith(\".nii.gz\")), None)\n",
    "if not basename:\n",
    "    raise FileNotFoundError(\"No NIfTI files found in the MRI directory.\")\n",
    "\n",
    "# Generate file paths\n",
    "image_file_path = os.path.join(test_mri_dir, basename)\n",
    "gt_file_path = os.path.join(ground_truth_dir, basename.replace(\"_0000\", \"\"))\n",
    "pred_file_path = os.path.join(predicted_masks_dir, basename.replace(\"_0000\", \"\"))\n",
    "\n",
    "# Load the images, ground truth, and predicted masks as numpy arrays\n",
    "mri_nifti = load_nifti_image(image_file_path)\n",
    "ground_truth_nifti = load_nifti_image(gt_file_path.replace('labelsTs', 'labelsTs_transformed'))\n",
    "predicted_nifti = load_nifti_image(pred_file_path)\n",
    "\n",
    "print(f\"Image shape: {mri_nifti.shape}\")\n",
    "print(f\"Ground Truth shape: {ground_truth_nifti.shape}\")\n",
    "print(f\"Prediction shape: {predicted_nifti.shape}\")\n",
    "\n",
    "# Apply the validation transforms to both the ground truth and predicted data\n",
    "img_transformed, gt_transformed = apply_test_transforms(image_file_path, gt_file_path, test_transforms)\n",
    "_, pred_transformed = apply_test_transforms(image_file_path, pred_file_path, test_transforms)\n",
    "\n",
    "# Ensure that the images and masks have the same shape\n",
    "if gt_transformed.shape != pred_transformed.shape:\n",
    "    print(f\"Shape mismatch: GT shape: {gt_transformed.shape}, Pred shape: {pred_transformed.shape}\")\n",
    "else:\n",
    "    # Plot the individual slices (original image, ground truth, predicted) with original image as background\n",
    "    visualize_slices_grid(mri_nifti, ground_truth_nifti, predicted_nifti)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medsam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
