{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5988c3b5",
   "metadata": {},
   "source": [
    "# UNETR Inference Pipeline\n",
    "This notebook demonstrates the inference process for UNETR-based models, showing how to load NIfTI files, preprocess data, apply transforms, and visualize results. The code is structured for clarity and reusability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a13ce5",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "### 1.1 Import Libraries\n",
    "\n",
    "We import necessary libraries for handling medical images, preprocessing, model inference, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b117bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "import scipy.ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import label\n",
    "\n",
    "# MONAI imports\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, ScaleIntensityRanged,\n",
    "    EnsureChannelFirstd, ResizeWithPadOrCropd\n",
    ")\n",
    "from monai.networks.nets import UNETR\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "\n",
    "# tqdm for progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "from calculate_result_metrics import calculate_result_metrics\n",
    "\n",
    "# Initialize the Dice metric\n",
    "dice_score_metric = DiceMetric(include_background=True, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54ca135",
   "metadata": {},
   "source": [
    "### 1.2 Define Paths and Directories\n",
    "Paths for the model, input MRIs, ground truth masks, and output predictions are set here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7386b2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define placeholders for file paths\n",
    "model_path = \"<MODEL_PATH>\"                     # Path to the trained model, e.g., 'path/to/best_model.pth'\n",
    "test_mri_dir = \"<MRI_DIR>\"                      # Path to the MRI test images, e.g., 'path/to/imagesTs'\n",
    "ground_truth_dir = \"<GROUND_TRUTH_DIR>\"         # Path to the ground truth masks, e.g., 'path/to/labelsTs'\n",
    "predicted_masks_dir = \"<PREDICTED_MASKS_DIR>\"   # Directory to save predicted masks, e.g., 'path/to/labelsTs_pred'\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(predicted_masks_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a994a18",
   "metadata": {},
   "source": [
    "## 2. Transformations\n",
    "\n",
    "### 2.1.Preprocessing Transformations\n",
    "Preprocessing transformations are applied to normalize intensity values, adjust channels, and resize images to the model's expected input size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1202e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated test_transforms with intensity scaling only applied to the image, not the label (mask)\n",
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"], allow_missing_keys=False),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        # Apply intensity scaling only to the image, not the label\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=16, \n",
    "            a_max=1668, # change accordingly to dataset\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        # Ensure validation images also match the expected size\n",
    "        ResizeWithPadOrCropd(keys=[\"image\", \"label\"], spatial_size=(224, 224, 64)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30237b2",
   "metadata": {},
   "source": [
    "### 2.2.Postprocessing Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb443ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_3d_holes(mask_3d):\n",
    "    \"\"\"\n",
    "    Fill internal holes in a 3D binary mask.\n",
    "\n",
    "    Args:\n",
    "        mask_3d (np.ndarray): 3D binary mask (1 for object, 0 for background).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Binary mask with internal holes filled.\n",
    "    \"\"\"\n",
    "    filled_mask = ndi.binary_fill_holes(mask_3d).astype(np.uint8)\n",
    "    return filled_mask\n",
    "\n",
    "def keep_largest_connected_component_3d(mask_3d):\n",
    "    \"\"\"\n",
    "    Keep only the largest connected component in a 3D binary mask.\n",
    "\n",
    "    Args:\n",
    "        mask_3d (np.ndarray): 3D binary mask (1 for object, 0 for background).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Binary mask with only the largest connected component in 3D.\n",
    "    \"\"\"\n",
    "    # Label connected components in 3D\n",
    "    labeled_mask = label(mask_3d, connectivity=3)\n",
    "    if labeled_mask.max() == 0:  # If no components are found, return the original mask\n",
    "        return mask_3d\n",
    "\n",
    "    # Find the largest connected component\n",
    "    largest_component = np.argmax(np.bincount(labeled_mask.flat)[1:]) + 1\n",
    "    largest_component_mask = (labeled_mask == largest_component).astype(np.uint8)\n",
    "    \n",
    "    return largest_component_mask\n",
    "\n",
    "\n",
    "def postprocess_predicted_mask(predicted_mask):\n",
    "    \"\"\"\n",
    "    Apply 3D post-processing steps to the predicted mask:\n",
    "    1. Fill internal holes in 3D.\n",
    "    2. Keep only the largest connected component in 3D.\n",
    "\n",
    "    Args:\n",
    "        predicted_mask (np.ndarray): 3D binary mask (1 for object, 0 for background).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Post-processed binary mask.\n",
    "    \"\"\"\n",
    "    # Step 1: Fill internal holes in 3D\n",
    "    filled_mask = fill_3d_holes(predicted_mask)\n",
    "\n",
    "    # Step 2: Keep the largest connected component in 3D\n",
    "    processed_mask = keep_largest_connected_component_3d(filled_mask)\n",
    "\n",
    "    return processed_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20767656",
   "metadata": {},
   "source": [
    "## 3. Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da345198",
   "metadata": {},
   "source": [
    "Check for GPU availability and set the device accordingly for efficient computation. Then load the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec1cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNETR(\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    img_size=(224, 224, 64),\n",
    "    feature_size=16,\n",
    "    hidden_size=768,\n",
    "    mlp_dim=3072,\n",
    "    num_heads=12,\n",
    "    proj_type=\"perceptron\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    dropout_rate=0.0,\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e7a40e",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "## 4. Model Inference\n",
    "\n",
    "This section performs segmentation on the test dataset using a pre-trained UNETR model. The function processes MRI images, applies transformations, runs model inference with sliding window, computes Dice scores, and optionally saves the predicted segmentation masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2033de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process the test set\n",
    "def process_test_set(test_mri_dir, predicted_masks_dir):\n",
    "    mri_files = sorted([os.path.join(test_mri_dir, f) for f in os.listdir(test_mri_dir) if f.endswith('.nii.gz')])\n",
    "\n",
    "    dice_scores = []\n",
    "\n",
    "    for mri_file in tqdm(mri_files):\n",
    "        gt_file = mri_file.replace(\"imagesTs\", \"labelsTs\").replace(\"_0000\", \"\")\n",
    "\n",
    "        # Load and preprocess MRI image and GT label\n",
    "        val_data = {\"image\": mri_file, \"label\": gt_file}\n",
    "        val_data = test_transforms(val_data)  # Apply transformations\n",
    "        mri_img = val_data[\"image\"]\n",
    "        gt_mask = val_data[\"label\"]\n",
    "\n",
    "        # Ensure the ground truth mask (GT) is binary\n",
    "        gt_mask_binary = torch.unsqueeze(gt_mask, 1).to(device)\n",
    "        gt_mask_binary = gt_mask_binary.squeeze(1)\n",
    "\n",
    "        unique_vals = np.unique(gt_mask_binary.cpu().numpy())\n",
    "        if len(unique_vals) > 1:\n",
    "            small_val = np.min(unique_vals)\n",
    "            gt_mask_binary = torch.where(gt_mask_binary == small_val, torch.tensor(0.0), torch.tensor(1.0))\n",
    "        else:\n",
    "            print(f\"GT mask contains a single unique value: {unique_vals}. Ensure the data is correct.\")\n",
    "\n",
    "        # Prepare MRI input for the model\n",
    "        mri_inputs = torch.unsqueeze(mri_img, 1).to(device)\n",
    "\n",
    "        # Perform sliding window inference\n",
    "        with torch.no_grad():\n",
    "            pred_outputs = sliding_window_inference(mri_inputs, (224, 224, 64), 4, model)\n",
    "        pred_outputs = torch.softmax(pred_outputs, dim=1)\n",
    "        pred_mask_argmax = torch.argmax(pred_outputs, dim=1)\n",
    "\n",
    "        # Post-process the predicted mask in 3D\n",
    "        processed_pred_mask = postprocess_predicted_mask(pred_mask_argmax.cpu().numpy()[0])\n",
    "\n",
    "        # Convert back to PyTorch tensor for Dice score calculation\n",
    "        processed_pred_tensor = torch.tensor(processed_pred_mask).unsqueeze(0).to(device)\n",
    "\n",
    "        # Calculate Dice score\n",
    "        dice_score_metric(y_pred=processed_pred_tensor, y=gt_mask_binary)\n",
    "        dice_score = dice_score_metric.aggregate().item()\n",
    "        dice_scores.append(dice_score)\n",
    "        dice_score_metric.reset()\n",
    "\n",
    "        # Save predicted mask as NIfTI\n",
    "        affine_matrix = val_data[\"image\"].meta[\"affine\"] if \"affine\" in val_data[\"image\"].meta else np.eye(4)\n",
    "        pred_nifti = nib.Nifti1Image(pred_mask_argmax.cpu().numpy()[0].astype(np.uint8), affine_matrix)\n",
    "\n",
    "        pred_nifti_name = os.path.basename(mri_file).replace(\"_0000\", \"\")\n",
    "        pred_nifti_path = os.path.join(predicted_masks_dir, pred_nifti_name)\n",
    "        nib.save(pred_nifti, pred_nifti_path)\n",
    "\n",
    "    return dice_scores\n",
    "\n",
    "# Process the dataset\n",
    "print(\"Processing Test Set...\")\n",
    "dice_scores = process_test_set(test_mri_dir, predicted_masks_dir)\n",
    "print(f\"Inference complete. Mean Dice Score: {np.mean(dice_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b48d13",
   "metadata": {},
   "source": [
    "## 4.Evaluate Model Performance\n",
    "\n",
    "This section uses the `calculate_result_metrics.py` script to evaluate the model's segmentation performance. The script calculates metrics (DICE, Hausdorff, Hausdorff95, S2S, RVE) and groups tumors by size using specified thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2025dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = \"[200,400]\"  # Thresholds for grouping tumors by size:\n",
    "                          # - <200: Small tumors\n",
    "                          # - 200-400: Medium tumors\n",
    "                          # - >400: Large tumors\n",
    "\n",
    "# Calculate result metrics \n",
    "try:\n",
    "    # Call the main function directly\n",
    "    calculate_result_metrics(gt_folder=ground_truth_dir, pred_folder=predicted_masks_dir, thresholds=thresholds)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during metrics calculation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d559efd",
   "metadata": {},
   "source": [
    "## 5. Visualize Results\n",
    "\n",
    "We visualize three key slices from the MRI:\n",
    "1. First Quarter Slice,\n",
    "2. Middle Slice,\n",
    "3. Third Quarter Slice.\n",
    "\n",
    "For each slice, the following are shown:\n",
    "1. Original MRI Image.\n",
    "2. Ground Truth Overlay.\n",
    "3. Predicted Mask Overlay.\n",
    "4. Combined Ground Truth and Prediction Overlay.\n",
    "\n",
    "The visualizations are presented in a grid layout for easy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2bc914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a NIfTI image\n",
    "def load_nifti_image(filepath):\n",
    "    image = sitk.ReadImage(filepath)\n",
    "    return sitk.GetArrayFromImage(image)\n",
    "\n",
    "# Function to apply the same validation transforms to both ground truth and predicted images\n",
    "def apply_test_transforms(image_file, label_file, test_transforms):\n",
    "    val_data = {\"image\": image_file, \"label\": label_file}\n",
    "    transformed = test_transforms(val_data)\n",
    "    return transformed[\"image\"], transformed[\"label\"]\n",
    "\n",
    "def visualize_slices_grid(image, ground_truth, prediction):\n",
    "    \"\"\"\n",
    "    Visualize slices in a grid:\n",
    "    1st row: First quarter slice\n",
    "    2nd row: Middle slice\n",
    "    3rd row: Third quarter slice\n",
    "\n",
    "    Each row contains:\n",
    "    1. Original Image\n",
    "    2. Ground Truth Overlay\n",
    "    3. Predicted Mask Overlay\n",
    "    4. Combined Overlay\n",
    "    \"\"\"\n",
    "    # Calculate slice indices dynamically\n",
    "    num_slices = image.shape[0]\n",
    "    slice_indices = [num_slices // 4, num_slices // 2, 3 * num_slices // 4]\n",
    "\n",
    "    plt.figure(figsize=(24, 18))  # Adjust figure size for three rows\n",
    "\n",
    "    for row_idx, slice_idx in enumerate(slice_indices):\n",
    "        # Extract slices\n",
    "        if len(image.shape) == 3:  # 3D MRI\n",
    "            image_slice = image[slice_idx, :, :]\n",
    "            gt_slice = ground_truth[slice_idx, :, :]\n",
    "            pred_slice = prediction[slice_idx, :, :]\n",
    "     \n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected image shape: {image.shape}\")\n",
    "\n",
    "        # Original Image\n",
    "        plt.subplot(3, 4, row_idx * 4 + 1)\n",
    "        plt.imshow(image_slice, cmap='gray')\n",
    "        plt.title(f'Original Image - Slice {slice_idx}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Ground Truth Overlay\n",
    "        plt.subplot(3, 4, row_idx * 4 + 2)\n",
    "        plt.imshow(image_slice, cmap='gray', alpha=0.8)\n",
    "        plt.imshow(gt_slice, cmap='Reds', alpha=0.2)\n",
    "        plt.title(f'Ground Truth - Slice {slice_idx}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Predicted Mask Overlay\n",
    "        plt.subplot(3, 4, row_idx * 4 + 3)\n",
    "        plt.imshow(image_slice, cmap='gray', alpha=0.8)\n",
    "        plt.imshow(pred_slice, cmap='Blues', alpha=0.2)\n",
    "        plt.title(f'Predicted Mask - Slice {slice_idx}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Combined Overlay (Ground Truth + Predicted)\n",
    "        plt.subplot(3, 4, row_idx * 4 + 4)\n",
    "        plt.imshow(image_slice, cmap='gray', alpha=0.8)\n",
    "        plt.imshow(gt_slice, cmap='Reds', alpha=0.2)\n",
    "        plt.imshow(pred_slice, cmap='Blues', alpha=0.2)\n",
    "        plt.title(f'Combined Overlay - Slice {slice_idx}')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a210d12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "basename = next((f for f in os.listdir(test_mri_dir) if f.endswith(\".nii.gz\")), None)\n",
    "if not basename:\n",
    "    raise FileNotFoundError(\"No NIfTI files found in the MRI directory.\")\n",
    "\n",
    "# Generate file paths\n",
    "image_file_path = os.path.join(test_mri_dir, basename)\n",
    "gt_file_path = os.path.join(ground_truth_dir, basename.replace(\"_0000\", \"\"))\n",
    "pred_file_path = os.path.join(predicted_masks_dir, basename.replace(\"_0000\", \"\"))\n",
    "\n",
    "# Load the images, ground truth, and predicted masks as numpy arrays\n",
    "mri_nifti = load_nifti_image(image_file_path)\n",
    "ground_truth_nifti = load_nifti_image(gt_file_path.replace('labelsTs', 'labelsTs_transformed'))\n",
    "predicted_nifti = load_nifti_image(pred_file_path)\n",
    "\n",
    "print(f\"Image shape: {mri_nifti.shape}\")\n",
    "print(f\"Ground Truth shape: {ground_truth_nifti.shape}\")\n",
    "print(f\"Prediction shape: {predicted_nifti.shape}\")\n",
    "\n",
    "# Apply the validation transforms to both the ground truth and predicted data\n",
    "img_transformed, gt_transformed = apply_test_transforms(image_file_path, gt_file_path, test_transforms)\n",
    "_, pred_transformed = apply_test_transforms(image_file_path, pred_file_path, test_transforms)\n",
    "\n",
    "# Ensure that the images and masks have the same shape\n",
    "if gt_transformed.shape != pred_transformed.shape:\n",
    "    print(f\"Shape mismatch: GT shape: {gt_transformed.shape}, Pred shape: {pred_transformed.shape}\")\n",
    "else:\n",
    "    # Plot the individual slices (original image, ground truth, predicted) with original image as background\n",
    "    visualize_slices_grid(mri_nifti, ground_truth_nifti, predicted_nifti)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnunetv2_sahika",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
